@software{Syzkaller,
  author={Google},
  title={Syzkaller},
  year={2022},
  url={https://github.com/google/syzkaller}
}

@article{prompt,
  author={},
  title={},
  url={https://www.promptingguide.ai/zh}
  }

@inproceedings{llvm,
author = {Lattner, Chris and Adve, Vikram},
title = {LLVM: A Compilation Framework for Lifelong Program Analysis \& Transformation},
year = {2004},
isbn = {0769521029},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper describes LLVM (Low Level Virtual Machine),a compiler framework designed to support transparent, lifelongprogram analysis and transformation for arbitrary programs,by providing high-level information to compilertransformations at compile-time, link-time, run-time, and inidle time between runs.LLVM defines a common, low-levelcode representation in Static Single Assignment (SSA) form,with several novel features: a simple, language-independenttype-system that exposes the primitives commonly used toimplement high-level language features; an instruction fortyped address arithmetic; and a simple mechanism that canbe used to implement the exception handling features ofhigh-level languages (and setjmp/longjmp in C) uniformlyand efficiently.The LLVM compiler framework and coderepresentation together provide a combination of key capabilitiesthat are important for practical, lifelong analysis andtransformation of programs.To our knowledge, no existingcompilation approach provides all these capabilities.We describethe design of the LLVM representation and compilerframework, and evaluate the design in three ways: (a) thesize and effectiveness of the representation, including thetype information it provides; (b) compiler performance forseveral interprocedural problems; and (c) illustrative examplesof the benefits LLVM provides for several challengingcompiler problems.},
booktitle = {Proceedings of the International Symposium on Code Generation and Optimization: Feedback-Directed and Runtime Optimization},
pages = {75},
location = {Palo Alto, California},
series = {CGO '04}
}

@inproceedings{SVF,
author = {Sui, Yulei and Xue, Jingling},
title = {SVF: interprocedural static value-flow analysis in LLVM},
year = {2016},
isbn = {9781450342414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2892208.2892235},
doi = {10.1145/2892208.2892235},
abstract = {This paper presents SVF, a tool that enables scalable and precise interprocedural Static Value-Flow analysis for C programs by leveraging recent advances in sparse analysis. SVF, which is fully implemented in LLVM, allows value-flow construction and pointer analysis to be performed in an iterative manner, thereby providing increasingly improved precision for both. SVF accepts points- to information generated by any pointer analysis (e.g., Andersen’s analysis) and constructs an interprocedural memory SSA form, in which the def-use chains of both top-level and address-taken variables are captured. Such value-flows can be subsequently exploited to support various forms of program analysis or enable more precise pointer analysis (e.g., flow-sensitive analysis) to be performed sparsely. By dividing a pointer analysis into three loosely coupled components: Graph, Rules and Solver, SVF provides an extensible interface for users to write their own solutions easily. SVF is publicly available at http://unsw-corg.github.io/SVF.},
booktitle = {Proceedings of the 25th International Conference on Compiler Construction},
pages = {265–266},
numpages = {2},
keywords = {Pointer Analysis, SVF, Value-Flow},
location = {Barcelona, Spain},
series = {CC '16}
}

@software{AFLPP,
author = {Heuse, Marc and Eißfeldt, Heiko and Fioraldi, Andrea and Maier, Dominik},
license = {AGPL-3.0-or-later},
month = jan,
title = {{AFL++}},
url = {https://github.com/AFLplusplus/AFLplusplus},
version = {4.00c},
year = {2022}
}

@software{AFL,
  author={Google},
  title={American Fuzzy Lop},
  year={2019},
  url={https://github.com/google/AFL}
}

@software{CWE-Bench-Java,
  author={Ziyang Li and Saikat Dutta and Mayur Naik},
  title={CWE-Bench-Java},
  year={2024},
  url={https://github.com/iris-sast/cwe-bench-java}
  }

@misc{IRIS,
      title={LLM-Assisted Static Analysis for Detecting Security Vulnerabilities}, 
      author={Ziyang Li and Saikat Dutta and Mayur Naik},
      year={2024},
      eprint={2405.17238},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2405.17238}, 
}

@article{Llift,
author = {Li, Haonan and Hao, Yu and Zhai, Yizhuo and Qian, Zhiyun},
title = {Enhancing Static Analysis for Practical Bug Detection: An LLM-Integrated Approach},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649828},
doi = {10.1145/3649828},
abstract = {While static analysis is instrumental in uncovering software bugs, its precision in analyzing large and intricate codebases remains challenging. The emerging prowess of Large Language Models (LLMs) offers a promising avenue to address these complexities. In this paper, we present LLift, a pioneering framework that synergizes static analysis and LLMs, with a spotlight on identifying use-before-initialization (UBI) bugs within the Linux kernel. Drawing from our insights into variable usage conventions in Linux, we enhance path analysis using post-constraint guidance. This approach, combined with our methodically crafted procedures, empowers LLift to adeptly handle the challenges of bug-specific modeling, extensive codebases, and the unpredictable nature of LLMs. Our real-world evaluations identified four previously undiscovered UBI bugs in the mainstream Linux kernel, which the Linux community has acknowledged. This study reaffirms the potential of marrying static analysis with LLMs, setting a compelling direction for future research in this area.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {111},
numpages = {26},
keywords = {Static analysis, bug detection, large language model}
}

@article{Andersen,
  title={Program analysis and specialization for the C programming language},
  author={Andersen, Lars Ole},
  year={1994},
  publisher={Citeseer}
}

@misc{misc,
      title={Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities}, 
      author={Avishree Khare and Saikat Dutta and Ziyang Li and Alaia Solko-Breslin and Rajeev Alur and Mayur Naik},
      year={2024},
      eprint={2311.16169},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2311.16169}, 
}

@inproceedings{GPTScan,
author = {Sun, Yuqiang and Wu, Daoyuan and Xue, Yue and Liu, Han and Wang, Haijun and Xu, Zhengzi and Xie, Xiaofei and Liu, Yang},
title = {GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639117},
doi = {10.1145/3597503.3639117},
abstract = {Smart contracts are prone to various vulnerabilities, leading to substantial financial losses over time. Current analysis tools mainly target vulnerabilities with fixed control- or data-flow patterns, such as re-entrancy and integer overflow. However, a recent study on Web3 security bugs revealed that about 80\% of these bugs cannot be audited by existing tools due to the lack of domain-specific property description and checking. Given recent advances in Large Language Models (LLMs), it is worth exploring how Generative Pre-training Transformer (GPT) could aid in detecting logic vulnerabilities.In this paper, we propose GPTScan, the first tool combining GPT with static analysis for smart contract logic vulnerability detection. Instead of relying solely on GPT to identify vulnerabilities, which can lead to high false positives and is limited by GPT's pre-trained knowledge, we utilize GPT as a versatile code understanding tool. By breaking down each logic vulnerability type into scenarios and properties, GPTScan matches candidate vulnerabilities with GPT. To enhance accuracy, GPTScan further instructs GPT to intelligently recognize key variables and statements, which are then validated by static confirmation. Evaluation on diverse datasets with around 400 contract projects and 3K Solidity files shows that GPTScan achieves high precision (over 90\%) for token contracts and acceptable precision (57.14\%) for large projects like Web3Bugs. It effectively detects ground-truth logic vulnerabilities with a recall of over 70\%, including 9 new vulnerabilities missed by human auditors. GPTScan is fast and cost-effective, taking an average of 14.39 seconds and 0.01 USD to scan per thousand lines of Solidity code. Moreover, static confirmation helps GPTScan reduce two-thirds of false positives.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {166},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
} 

@inproceedings {DriFuzz,
author = {Zekun Shen and Ritik Roongta and Brendan Dolan-Gavitt},
title = {Drifuzz: Harvesting Bugs in Device Drivers from Golden Seeds},
booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
year = {2022},
isbn = {978-1-939133-31-1},
address = {Boston, MA},
pages = {1275--1290},
url = {https://www.usenix.org/conference/usenixsecurity22/presentation/shen-zekun},
publisher = {USENIX Association},
month = aug
}

@inproceedings {StateFuzz,
author = {Bodong Zhao and Zheming Li and Shisong Qin and Zheyu Ma and Ming Yuan and Wenyu Zhu and Zhihong Tian and Chao Zhang},
title = {{StateFuzz}: System {Call-Based} {State-Aware} Linux Driver Fuzzing},
booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
year = {2022},
isbn = {978-1-939133-31-1},
address = {Boston, MA},
pages = {3273--3289},
url = {https://www.usenix.org/conference/usenixsecurity22/presentation/zhao-bodong},
publisher = {USENIX Association},
month = aug
}

@inproceedings{Snowboard,
author = {Gong, Sishuai and Altinb\"{u}ken, Deniz and Fonseca, Pedro and Maniatis, Petros},
title = {Snowboard: Finding Kernel Concurrency Bugs through Systematic Inter-thread Communication Analysis},
year = {2021},
isbn = {9781450387095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477132.3483549},
doi = {10.1145/3477132.3483549},
abstract = {Kernel concurrency bugs are challenging to find because they depend on very specific thread interleavings and test inputs. While separately exploring kernel thread interleavings or test inputs has been closely examined, jointly exploring interleavings and test inputs has received little attention, in part due to the resulting vast search space. Using precious, limited testing resources to explore this search space and execute just the right concurrent tests in the proper order is critical.This paper proposes Snowboard a testing framework that generates and executes concurrent tests by intelligently exploring thread interleavings and test inputs jointly. The design of Snowboard is based on a concept called potential memory communication (PMC), a guess about pairs of tests that, when executed concurrently, are likely to perform memory accesses to shared addresses, which in turn may trigger concurrency bugs. To identify PMCs, Snowboard runs tests sequentially from a fixed initial kernel state, collecting their memory accesses. It then pairs up tests that write and read the same region into candidate concurrent tests. It executes those tests using the associated PMC as a scheduling hint to focus interleaving search only on those schedules that directly affect the relevant memory accesses. By clustering candidate tests on various features of their PMCs, Snowboard avoids testing similar behaviors, which would be inefficient. Finally, by executing tests from small clusters first, it prioritizes uncommon suspicious behaviors that may have received less scrutiny.Snowboard discovered 14 new concurrency bugs in Linux kernels 5.3.10 and 5.12-rc3, of which 12 have been confirmed by developers. Six of these bugs cause kernel panics and filesystem errors, and at least two have existed in the kernel for many years, showing that this approach can uncover hard-to-find, critical bugs. Furthermore, we show that covering as many distinct pairs of uncommon read/write instructions as possible is the test-prioritization strategy with the highest bug yield for a given test-time budget.},
booktitle = {Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles},
pages = {66–83},
numpages = {18},
keywords = {Concurrency programming, Kernel concurrency bug, Operating systems security, Software testing and debugging},
location = {Virtual Event, Germany},
series = {SOSP '21}
}

@inproceedings{Snowcat,
author = {Gong, Sishuai and Peng, Dinglan and Alt\i{}nb\"{u}ken, Deniz and Fonseca, Pedro and Maniatis, Petros},
title = {Snowcat: Efficient Kernel Concurrency Testing using a Learned Coverage Predictor},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600006.3613148},
doi = {10.1145/3600006.3613148},
abstract = {Random-based approaches and heuristics are commonly used in kernel concurrency testing due to the massive scale of modern kernels and corresponding interleaving space. The lack of accurate and scalable approaches to analyze concurrent kernel executions makes existing testing approaches heavily rely on expensive dynamic executions to measure the effectiveness of a new test. Unfortunately, the high cost incurred by dynamic executions limits the breadth of the exploration and puts latency pressure on finding effective concurrent test inputs and schedules, hindering the overall testing effectiveness.This paper proposes Snowcat, a kernel concurrency testing framework that generates effective test inputs and schedules using a learned kernel block-coverage predictor. Using a graph neural network, the coverage predictor takes a concurrent test input and scheduling hints and outputs a prediction on whether certain important code blocks will be executed. Using this predictor, Snowcat can skip concurrent tests that are likely to be fruitless and prioritize the promising ones for actual dynamic execution.After testing the Linux kernel for over a week, Snowcat finds ~17\% more potential data races, by prioritizing tests of more fruitful schedules than existing work would have chosen. Snowcat can also find effective test inputs that expose new concurrency bugs with higher probability (1.4\texttimes{}~2.6\texttimes{}), or reproduce known bugs more quickly (15\texttimes{}) than state-of-art testing tools. More importantly, Snowcat is shown to be more efficient at reaching a desirable level of race coverage in the continuous setting, as the Linux kernel evolves from version to version. In total, Snowcat discovered 17 new concurrency bugs in Linux kernel 6.1, of which 13 are confirmed and 6 are fixed.},
booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles},
pages = {35–51},
numpages = {17},
keywords = {kernel concurrency bugs, operating systems security, software testing and debugging, concurrency programming},
location = {Koblenz, Germany},
series = {SOSP '23}
}

@INPROCEEDINGS{Razzer,
  author={Jeong, Dae R. and Kim, Kyungtae and Shivakumar, Basavesh and Lee, Byoungyoung and Shin, Insik},
  booktitle={2019 IEEE Symposium on Security and Privacy (SP)}, 
  title={Razzer: Finding Kernel Race Bugs through Fuzzing}, 
  year={2019},
  volume={},
  number={},
  pages={754-768},
  keywords={Kernel;Instruction sets;Fuzzing;Tools;Computer bugs;Security;Static analysis;data-race;fuzzing;kernel;race-bugs},
  doi={10.1109/SP.2019.00017}
}

@inproceedings {LR-Miner,
author = {Tuo Li and Jia-Ju Bai and Gui-Dong Han and Shi-Min Hu},
title = {{LR-Miner}: Static Race Detection in {OS} Kernels by Mining Locking Rules},
booktitle = {33rd USENIX Security Symposium (USENIX Security 24)},
year = {2024},
isbn = {978-1-939133-44-1},
address = {Philadelphia, PA},
pages = {6149--6166},
url = {https://www.usenix.org/conference/usenixsecurity24/presentation/li-tuo},
publisher = {USENIX Association},
month = aug
}

@inproceedings{RacerX,
author = {Engler, Dawson and Ashcraft, Ken},
title = {RacerX: effective, static detection of race conditions and deadlocks},
year = {2003},
isbn = {1581137575},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/945445.945468},
doi = {10.1145/945445.945468},
abstract = {This paper describes RacerX, a static tool that uses flow-sensitive, interprocedural analysis to detect both race conditions and deadlocks. It is explicitly designed to find errors in large, complex multithreaded systems. It aggressively infers checking information such as which locks protect which operations, which code contexts are multithreaded, and which shared accesses are dangerous. It tracks a set of code features which it uses to sort errors both from most to least severe. It uses novel techniques to counter the impact of analysis mistakes. The tool is fast, requiring between 2-14 minutes to analyze a 1.8 million line system. We have applied it to Linux, FreeBSD, and a large commercial code base, finding serious errors in all of them. RacerX is a static tool that uses flow-sensitive, interprocedural analysis to detect both race conditions and deadlocks. It uses novel strategies to infer checking information such as which locks protect which operations, which code contexts are multithreaded, and which shared accesses are dangerous. We applied it to FreeBSD, Linux and a large commercial code base and found serious errors in all of them.},
booktitle = {Proceedings of the Nineteenth ACM Symposium on Operating Systems Principles},
pages = {237–252},
numpages = {16},
keywords = {deadlock detection, program checking, race detection},
location = {Bolton Landing, NY, USA},
series = {SOSP '03}
}

@inproceedings{LockDoc,
author = {Lochmann, Alexander and Schirmeier, Horst and Borghorst, Hendrik and Spinczyk, Olaf},
title = {LockDoc: Trace-Based Analysis of Locking in the Linux Kernel},
year = {2019},
isbn = {9781450362818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3302424.3303948},
doi = {10.1145/3302424.3303948},
abstract = {For fine-grained synchronization of application and kernel threads, the Linux kernel provides a multitude of different locking mechanisms that are being used on various individually locked data structures. Understanding which locks are required in which order for a particular member variable of a kernel data structure has become truly difficult, even for Linux-kernel experts themselves.In this paper we introduce LockDoc -- an approach that, based on the analysis of execution traces of an instrumented Linux kernel, automatically deduces the most likely locking rule for all members of arbitrary kernel data structures. From these locking rules, LockDoc generates documentation that supports kernel developers and helps avoiding concurrency bugs. Additionally, the (very limited) existing documentation can be verified, and locking-rule violations -- potential bugs in the kernel code -- can be found.Our results include generated locking rules for previously predominantly undocumented member variables of 11 different Linux-kernel data structures. Manually inspecting the scarce source-code documentation for five of these data structures reveals that only 53 percent of the variables with a documented locking rule are actually consistently accessed with the required locks held. This indicates possible documentation or synchronization bugs in the Linux kernel, of which one has already been confirmed by kernel experts.},
booktitle = {Proceedings of the Fourteenth EuroSys Conference 2019},
articleno = {11},
numpages = {15},
location = {Dresden, Germany},
series = {EuroSys '19}
}

@inproceedings {Dr.Checker,
author = {Aravind Machiry and Chad Spensky and Jake Corina and Nick Stephens and Christopher Kruegel and Giovanni Vigna},
title = {{DR}. {CHECKER}: A Soundy Analysis for Linux Kernel Drivers},
booktitle = {26th USENIX Security Symposium (USENIX Security 17)},
year = {2017},
isbn = {978-1-931971-40-9},
address = {Vancouver, BC},
pages = {1007--1024},
url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/machiry},
publisher = {USENIX Association},
month = aug
}

@inproceedings{OFence,
author = {Lepers, Baptiste and Giet, Josselin and Zwaenepoel, Willy and Lawall, Julia},
title = {OFence: Pairing Barriers to Find Concurrency Bugs in the Linux Kernel},
year = {2023},
isbn = {9781450394871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552326.3567504},
doi = {10.1145/3552326.3567504},
abstract = {Knowing which functions may execute concurrently is key to finding concurrency-related bugs. Existing tools infer the possibility of concurrency using dynamic analysis or by pairing functions that use the same locks. Code that relies on more relaxed concurrency controls is, by and large, out of the reach of existing concurrency-related bug-tracking tools.In this paper, we propose a new heuristic to automatically infer the possibility of concurrency in lockless code that relies on memory barriers (memory fences) for correctness, a task made complex by the fact that barriers do not have a unique identifier and do not have a clearly delimited scope.To infer the possibility of concurrency between barriers, we propose a novel heuristic based on matching objects accessed before and after barriers. Our approach is based on the observation that barriers work in pairs: if a write memory barrier orders writes to a set of objects, then there should be a read barrier that orders reads to the same set of objects. This pairing strategy allows us to infer which barriers are meant to run concurrently and, in turn, check the code surrounding the barriers for concurrency-related bugs. As a example of a type of concurrency bug, we focus on bugs related to the incorrect placement of reads or writes relative to barriers. When we detect incorrect read or write placements in the code, we automatically produce a patch to fix them.We evaluate our heuristic on the Linux kernel. Our analysis runs in 8 minutes. We fixed 12 incorrect ordering constraints that could have resulted in hard-to-debug data corruption or kernel crashes. The patches have been merged in the mainline kernel. None of the bugs could have been found using existing static analysis heuristics.},
booktitle = {Proceedings of the Eighteenth European Conference on Computer Systems},
pages = {33–45},
numpages = {13},
keywords = {kernel, memory barrier, static analysis},
location = {Rome, Italy},
series = {EuroSys '23}
}

@inproceedings {DCUAF,
author = {Jia-Ju Bai and Julia Lawall and Qiu-Liang Chen and Shi-Min Hu},
title = {Effective Static Analysis of Concurrency {Use-After-Free} Bugs in Linux Device Drivers},
booktitle = {2019 USENIX Annual Technical Conference (USENIX ATC 19)},
year = {2019},
isbn = {978-1-939133-03-8},
address = {Renton, WA},
pages = {255-268},
url = {https://www.usenix.org/conference/atc19/presentation/bai},
publisher = {USENIX Association},
month = jul
}

@INPROCEEDINGS{WHOOP,
  author={Deligiannis, Pantazis and Donaldson, Alastair F. and Rakamaric, Zvonimir},
  booktitle={2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Fast and Precise Symbolic Analysis of Concurrency Bugs in Device Drivers (T)}, 
  year={2015},
  volume={},
  number={},
  pages={166-177},
  keywords={Concurrent computing;Programming;Linux;Computer bugs;Kernel;Instruction sets;Context},
  doi={10.1109/ASE.2015.30}}

@inproceedings {DLOS,
author = {Jia-Ju Bai and Tuo Li and Shi-Min Hu},
title = {{DLOS}: Effective Static Detection of Deadlocks in {OS} Kernels},
booktitle = {2022 USENIX Annual Technical Conference (USENIX ATC 22)},
year = {2022},
isbn = {978-1-939133-29-47},
address = {Carlsbad, CA},
pages = {367--382},
url = {https://www.usenix.org/conference/atc22/presentation/bai},
publisher = {USENIX Association},
month = jul
}

@INPROCEEDINGS{PLA,
  author={Ryan, Gabriel and Shah, Abhishek and She, Dongdong and Jana, Suman},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)}, 
  title={Precise Detection of Kernel Data Races with Probabilistic Lockset Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={2086-2103},
  keywords={Schedules;Privacy;Linux;Memory management;Programmable logic arrays;Fuzzing;Probabilistic logic;systems-security;kernel-security;concurrent-program-testing;software-testing},
  doi={10.1109/SP46215.2023.10179366}}

@article{HBFourier,
author = {Ryan, Gabriel and Cetin, Burcu and Lim, Yongwhan and Jana, Suman},
title = {Accurate Data Race Prediction in the Linux Kernel through Sparse Fourier Learning},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649840},
doi = {10.1145/3649840},
abstract = {Testing for data races in the Linux OS kernel is challenging because there is an exponentially large space of system calls and thread interleavings that can potentially lead to concurrent executions with races. In this work, we introduce a new approach for modeling execution trace feasibility and apply it to Linux OS Kernel race prediction. To address the fundamental scalability challenge posed by the exponentially large domain of possible execution traces, we decompose the task of predicting trace feasibility into independent prediction subtasks encoded as learning Boolean indicator functions for specific memory accesses, and apply a sparse fourier learning approach to learning each feasibility subtask.  

Boolean functions that are sparse in their fourier domain can be efficiently learned by estimating the coefficients of their fourier expansion. Since the feasibility of each memory access depends on only a few other relevant memory accesses or system calls (e.g., relevant inter-thread communications), we observe that trace feasibility functions often have this sparsity property and can be learned efficiently. We use learned trace feasibility functions in conjunction with conservative alias analysis to implement a kernel race-testing system, HBFourier, that uses sparse fourier learning to efficiently model feasibility when making predictions. We evaluate our approach on a recent Linux development kernel and show it finds 44 more races with 15.7\% more accurate race predictions than the next best performing system in our evaluation, in addition to identifying 5 new race bugs confirmed by kernel developers.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {123},
numpages = {23},
keywords = {Data Race Prediction, Linux Kernel Testing, Sparse Fourier Learning}
}

@INPROCEEDINGS{SEGFUZZ,
  author={Jeong, Dae R. and Lee, Byoungyoung and Shin, Insik and Kwon, Youngjin},
  booktitle={2023 IEEE Symposium on Security and Privacy (SP)}, 
  title={SegFuzz: Segmentizing Thread Interleaving to Discover Kernel Concurrency Bugs through Fuzzing}, 
  year={2023},
  volume={},
  number={},
  pages={2104-2121},
  keywords={Concurrent computing;Privacy;Linux;Computer bugs;Fuzzing;Space exploration;Security;fuzzing;kernel;concurrency-bug;operating-systems-security;software-testing},
  doi={10.1109/SP46215.2023.10179398}}

@inproceedings {IMMI,
author = {Dinghao Liu and Zhipeng Lu and Shouling Ji and Kangjie Lu and Jianhai Chen and Zhenguang Liu and Dexin Liu and Renyi Cai and Qinming He},
title = {Detecting Kernel Memory Bugs through Inconsistent Memory Management Intention Inferences},
booktitle = {33rd USENIX Security Symposium (USENIX Security 24)},
year = {2024},
isbn = {978-1-939133-44-1},
address = {Philadelphia, PA},
pages = {4069--4086},
url = {https://www.usenix.org/conference/usenixsecurity24/presentation/liu-dinghao-detecting},
publisher = {USENIX Association},
month = aug
}